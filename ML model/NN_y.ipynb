{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/Users/ye/Desktop/ACC/df.parquet', engine='pyarrow')\n",
    "df['proc'] = df['proc'].apply(lambda x: 1 if x != 0 else 0)\n",
    "Y = df['proc'].values\n",
    "X = df.drop(columns=['proc']).values\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassificationModel(nn.Module):\n",
    "    def __init__(self, input_features, hidden_layers):\n",
    "        super(BinaryClassificationModel, self).__init__()\n",
    "        self.layer0 = nn.Linear(input_features, hidden_layers[0])\n",
    "        self.layer1 = nn.Linear(hidden_layers[0], hidden_layers[1])\n",
    "        self.layer2 = nn.Linear(hidden_layers[1], 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer0(x))\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = self.sigmoid(self.layer2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1000\n",
    "num_epochs = 200\n",
    "hidden_layers = [32,16]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model instance\n",
    "models = BinaryClassificationModel(input_features=X.shape[1], hidden_layers=[64, 32])\n",
    "# create the quantized model instance\n",
    "model_quant = torch.ao.quantization.quantize_dynamic(\n",
    "    models,\n",
    "    {nn.Linear}, # the sets f layers to dynamically qunatize\n",
    "    dtype=torch.qint8 # the target dtype for qunatized weights\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the floating point version of this module:\n",
      "BinaryClassificationModel(\n",
      "  (layer0): Linear(in_features=142, out_features=64, bias=True)\n",
      "  (layer1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (layer2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "\n",
      "and now the quantized version:\n",
      "BinaryClassificationModel(\n",
      "  (layer0): DynamicQuantizedLinear(in_features=142, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (layer1): DynamicQuantizedLinear(in_features=64, out_features=32, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (layer2): DynamicQuantizedLinear(in_features=32, out_features=1, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print('Here is the floating point version of this module:')\n",
    "print(models)\n",
    "print('')\n",
    "print('and now the quantized version:')\n",
    "print(model_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the Model Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  fp32  \t Size (KB): 45.8349609375\n",
      "model:  int8  \t Size (KB): 15.0634765625\n",
      "3.043 times smaller\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def model_size(model, label=''):\n",
    "    \"\"\"\n",
    "    Calculate and print the size of a PyTorch model's parameters in kilobytes (KB).\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The PyTorch model whose size is to be calculated.\n",
    "    - label: An optional label to identify the model in the output (default is an empty string).\n",
    "    \n",
    "    Returns:\n",
    "    - The size of the model in bytes.\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), \"mymodel.p\")\n",
    "    # size reflects the amount of storage needed to save the model's parameters.\n",
    "    size = os.path.getsize(\"mymodel.p\")\n",
    "    print(\"model: \",label,' \\t','Size (KB):', size/1024) # the bytes are divide by 1024 to convert to kilobytes in binary terms\n",
    "    os.remove(\"mymodel.p\")\n",
    "    return size\n",
    "\n",
    "# compare the size\n",
    "f = model_size(models, \"fp32\") # size of the full precision model\n",
    "q = model_size(model_quant, \"int8\") # size of the quantized model\n",
    "print(\"{0:.3f} times smaller\".format(f/q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # batch size \n",
    "input_features = X.shape[1]  #  number of input features \n",
    "inputs = torch.randn(batch_size, input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 µs ± 3.98 µs per loop (mean ± std. dev. of 3 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 3 -n 1000 models.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floating point FP32\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (tuple, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!tuple of (int, int)!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!tuple of (int, int)!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zr/4gzc_dcx4_5ddc8wy4z_fllm0000gn/T/ipykernel_8754/2421629515.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Floating point FP32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.forward(inputs)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2362\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2363\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2364\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2365\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (tuple, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!tuple of (int, int)!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!tuple of (int, int)!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n"
     ]
    }
   ],
   "source": [
    "print(\"Floating point FP32\")\n",
    "inputs = X.shape\n",
    "%timeit model.forward(inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.resnet18(pretrained=True)\n",
    "# model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'module' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zr/4gzc_dcx4_5ddc8wy4z_fllm0000gn/T/ipykernel_8754/1760986324.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_qconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'qnnpack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# prepare the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_prepared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/ao/quantization/quantize.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(model, inplace, allow_list, observer_non_leaf_module_list, prepare_custom_config_dict)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;31m# TODO: remove allow_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreductor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                         \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreductor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                         \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'module' object"
     ]
    }
   ],
   "source": [
    "# set the quantisation configuration for the model\n",
    "models.qconfig = torch.quantization.get_default_qconfig('qnnpack')\n",
    "# prepare the model \n",
    "model_prepared = torch.quantization.prepare(models, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the prepared model to a quantized model\n",
    "model_quantized = torch.quantization.convert(model_prepared, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 143)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function for model training\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    \"\"\"\n",
    "    Train a given model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to be trained.\n",
    "    - train_loader: DataLoader for the training data.\n",
    "    - criterion: Loss function.\n",
    "    - optimizer: Optimization algorithm.\n",
    "    - num_epochs: Number of epochs to train the model.\n",
    "\n",
    "    Returns:\n",
    "    - losses: List of loss values per epoch.\n",
    "    \"\"\"\n",
    "    losses = []  # To store loss at each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [64, 142]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zr/4gzc_dcx4_5ddc8wy4z_fllm0000gn/T/ipykernel_8754/1502805417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss_quntized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_quantized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/zr/4gzc_dcx4_5ddc8wy4z_fllm0000gn/T/ipykernel_8754/3712672092.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [64, 142]"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_quntized = train_model(model_quantized, train_loader, criterion, optimizer, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9125992059707642\n",
      "Epoch 2, Loss: 0.6995591521263123\n",
      "Epoch 3, Loss: 2.1680243015289307\n",
      "Epoch 4, Loss: 0.4269472360610962\n",
      "Epoch 5, Loss: 2.256359338760376\n",
      "Epoch 6, Loss: 0.5562547445297241\n",
      "Epoch 7, Loss: 0.5179117918014526\n",
      "Epoch 8, Loss: 0.5085573792457581\n",
      "Epoch 9, Loss: 0.6116062998771667\n",
      "Epoch 10, Loss: 0.4852801561355591\n",
      "Epoch 11, Loss: 0.46259045600891113\n",
      "Epoch 12, Loss: 0.5649406909942627\n",
      "Epoch 13, Loss: 0.5077359676361084\n",
      "Epoch 14, Loss: 0.4745936095714569\n",
      "Epoch 15, Loss: 0.590796709060669\n",
      "Epoch 16, Loss: 0.6771931648254395\n",
      "Epoch 17, Loss: 0.5197178721427917\n",
      "Epoch 18, Loss: 0.6066542863845825\n",
      "Epoch 19, Loss: 0.7971432209014893\n",
      "Epoch 20, Loss: 2.167032480239868\n",
      "Epoch 21, Loss: 0.5671040415763855\n",
      "Epoch 22, Loss: 0.4715695083141327\n",
      "Epoch 23, Loss: 0.6161985993385315\n",
      "Epoch 24, Loss: 0.610099732875824\n",
      "Epoch 25, Loss: 0.5230613350868225\n",
      "Epoch 26, Loss: 0.4782036244869232\n",
      "Epoch 27, Loss: 0.48619306087493896\n",
      "Epoch 28, Loss: 2.090264081954956\n",
      "Epoch 29, Loss: 0.6362587213516235\n",
      "Epoch 30, Loss: 2.0749247074127197\n",
      "Epoch 31, Loss: 0.5572152137756348\n",
      "Epoch 32, Loss: 0.5342309474945068\n",
      "Epoch 33, Loss: 0.5568434000015259\n",
      "Epoch 34, Loss: 0.46358588337898254\n",
      "Epoch 35, Loss: 0.5521880984306335\n",
      "Epoch 36, Loss: 0.6120778918266296\n",
      "Epoch 37, Loss: 0.5545442700386047\n",
      "Epoch 38, Loss: 0.4623682200908661\n",
      "Epoch 39, Loss: 0.6074751019477844\n",
      "Epoch 40, Loss: 0.5164826512336731\n",
      "Epoch 41, Loss: 0.6866974830627441\n",
      "Epoch 42, Loss: 0.5752947926521301\n",
      "Epoch 43, Loss: 0.5702675580978394\n",
      "Epoch 44, Loss: 0.6159834265708923\n",
      "Epoch 45, Loss: 0.6964030861854553\n",
      "Epoch 46, Loss: 0.42903563380241394\n",
      "Epoch 47, Loss: 0.664595901966095\n",
      "Epoch 48, Loss: 0.5621854662895203\n",
      "Epoch 49, Loss: 0.597877025604248\n",
      "Epoch 50, Loss: 0.4737173020839691\n",
      "Epoch 51, Loss: 0.415991872549057\n",
      "Epoch 52, Loss: 0.4844377636909485\n",
      "Epoch 53, Loss: 0.5509591698646545\n",
      "Epoch 54, Loss: 0.41676634550094604\n",
      "Epoch 55, Loss: 0.48846977949142456\n",
      "Epoch 56, Loss: 0.5170626044273376\n",
      "Epoch 57, Loss: 0.5139589905738831\n",
      "Epoch 58, Loss: 0.44493091106414795\n",
      "Epoch 59, Loss: 0.6632631421089172\n",
      "Epoch 60, Loss: 0.5321734547615051\n",
      "Epoch 61, Loss: 0.5004618167877197\n",
      "Epoch 62, Loss: 0.3978007733821869\n",
      "Epoch 63, Loss: 0.5968837738037109\n",
      "Epoch 64, Loss: 0.45722460746765137\n",
      "Epoch 65, Loss: 0.6945301294326782\n",
      "Epoch 66, Loss: 0.5654563307762146\n",
      "Epoch 67, Loss: 0.5152407288551331\n",
      "Epoch 68, Loss: 0.5315299034118652\n",
      "Epoch 69, Loss: 0.4998687207698822\n",
      "Epoch 70, Loss: 0.418189138174057\n",
      "Epoch 71, Loss: 0.46209535002708435\n",
      "Epoch 72, Loss: 0.44025346636772156\n",
      "Epoch 73, Loss: 0.5874017477035522\n",
      "Epoch 74, Loss: 0.4973312020301819\n",
      "Epoch 75, Loss: 0.5692256689071655\n",
      "Epoch 76, Loss: 0.43572717905044556\n",
      "Epoch 77, Loss: 0.5149136185646057\n",
      "Epoch 78, Loss: 0.5092915892601013\n",
      "Epoch 79, Loss: 0.47215893864631653\n",
      "Epoch 80, Loss: 0.5397785305976868\n",
      "Epoch 81, Loss: 0.4771087169647217\n",
      "Epoch 82, Loss: 0.535724401473999\n",
      "Epoch 83, Loss: 0.4451024532318115\n",
      "Epoch 84, Loss: 0.6065874695777893\n",
      "Epoch 85, Loss: 0.5081700086593628\n",
      "Epoch 86, Loss: 0.6195663809776306\n",
      "Epoch 87, Loss: 0.561400294303894\n",
      "Epoch 88, Loss: 0.5226108431816101\n",
      "Epoch 89, Loss: 0.4820595383644104\n",
      "Epoch 90, Loss: 0.4508762061595917\n",
      "Epoch 91, Loss: 0.530204713344574\n",
      "Epoch 92, Loss: 0.5654513835906982\n",
      "Epoch 93, Loss: 0.5023761987686157\n",
      "Epoch 94, Loss: 0.6395220756530762\n",
      "Epoch 95, Loss: 0.5222601890563965\n",
      "Epoch 96, Loss: 0.5806357860565186\n",
      "Epoch 97, Loss: 0.48828405141830444\n",
      "Epoch 98, Loss: 0.48225581645965576\n",
      "Epoch 99, Loss: 0.5676635503768921\n",
      "Epoch 100, Loss: 0.5538505911827087\n",
      "Epoch 101, Loss: 0.5333563685417175\n",
      "Epoch 102, Loss: 0.5116229057312012\n",
      "Epoch 103, Loss: 0.44857490062713623\n",
      "Epoch 104, Loss: 0.4960886240005493\n",
      "Epoch 105, Loss: 0.45483100414276123\n",
      "Epoch 106, Loss: 0.4471723139286041\n",
      "Epoch 107, Loss: 0.40781641006469727\n",
      "Epoch 108, Loss: 0.5286084413528442\n",
      "Epoch 109, Loss: 0.46577709913253784\n",
      "Epoch 110, Loss: 0.5211732387542725\n",
      "Epoch 111, Loss: 0.479907751083374\n",
      "Epoch 112, Loss: 0.5937919616699219\n",
      "Epoch 113, Loss: 0.478850781917572\n",
      "Epoch 114, Loss: 0.5097777247428894\n",
      "Epoch 115, Loss: 0.4631529450416565\n",
      "Epoch 116, Loss: 0.5163248181343079\n",
      "Epoch 117, Loss: 0.46322664618492126\n",
      "Epoch 118, Loss: 0.37756845355033875\n",
      "Epoch 119, Loss: 0.5719778537750244\n",
      "Epoch 120, Loss: 0.41440799832344055\n",
      "Epoch 121, Loss: 0.5231544375419617\n",
      "Epoch 122, Loss: 0.44200456142425537\n",
      "Epoch 123, Loss: 0.47150522470474243\n",
      "Epoch 124, Loss: 0.41290318965911865\n",
      "Epoch 125, Loss: 0.5730491280555725\n",
      "Epoch 126, Loss: 0.3938620984554291\n",
      "Epoch 127, Loss: 0.46701791882514954\n",
      "Epoch 128, Loss: 0.46548983454704285\n",
      "Epoch 129, Loss: 0.4333527982234955\n",
      "Epoch 130, Loss: 0.5421174168586731\n",
      "Epoch 131, Loss: 0.5777369141578674\n",
      "Epoch 132, Loss: 0.4922434091567993\n",
      "Epoch 133, Loss: 0.44263771176338196\n",
      "Epoch 134, Loss: 0.48058050870895386\n",
      "Epoch 135, Loss: 0.40718549489974976\n",
      "Epoch 136, Loss: 0.42971158027648926\n",
      "Epoch 137, Loss: 0.38664382696151733\n",
      "Epoch 138, Loss: 0.52778160572052\n",
      "Epoch 139, Loss: 0.39809650182724\n",
      "Epoch 140, Loss: 0.3647731840610504\n",
      "Epoch 141, Loss: 0.4877099394798279\n",
      "Epoch 142, Loss: 0.4243631362915039\n",
      "Epoch 143, Loss: 0.423829585313797\n",
      "Epoch 144, Loss: 0.43457260727882385\n",
      "Epoch 145, Loss: 0.47107380628585815\n",
      "Epoch 146, Loss: 0.5179277658462524\n",
      "Epoch 147, Loss: 0.40232178568840027\n",
      "Epoch 148, Loss: 0.4076670706272125\n",
      "Epoch 149, Loss: 0.35560446977615356\n",
      "Epoch 150, Loss: 0.43999183177948\n",
      "Epoch 151, Loss: 0.3615177571773529\n",
      "Epoch 152, Loss: 0.32430022954940796\n",
      "Epoch 153, Loss: 0.38612252473831177\n",
      "Epoch 154, Loss: 0.45211654901504517\n",
      "Epoch 155, Loss: 0.4551278054714203\n",
      "Epoch 156, Loss: 0.406017929315567\n",
      "Epoch 157, Loss: 0.4635286331176758\n",
      "Epoch 158, Loss: 0.38400447368621826\n",
      "Epoch 159, Loss: 0.4203126132488251\n",
      "Epoch 160, Loss: 0.3292396366596222\n",
      "Epoch 161, Loss: 0.3516336679458618\n",
      "Epoch 162, Loss: 0.3756173849105835\n",
      "Epoch 163, Loss: 0.4370269775390625\n",
      "Epoch 164, Loss: 0.41836827993392944\n",
      "Epoch 165, Loss: 0.32883185148239136\n",
      "Epoch 166, Loss: 0.374570369720459\n",
      "Epoch 167, Loss: 0.5141420960426331\n",
      "Epoch 168, Loss: 0.4525347948074341\n",
      "Epoch 169, Loss: 0.5138241648674011\n",
      "Epoch 170, Loss: 0.3891203999519348\n",
      "Epoch 171, Loss: 0.36716368794441223\n",
      "Epoch 172, Loss: 0.49807438254356384\n",
      "Epoch 173, Loss: 0.43188533186912537\n",
      "Epoch 174, Loss: 0.42021438479423523\n",
      "Epoch 175, Loss: 0.345230370759964\n",
      "Epoch 176, Loss: 0.3442167341709137\n",
      "Epoch 177, Loss: 0.32432472705841064\n",
      "Epoch 178, Loss: 0.3978497385978699\n",
      "Epoch 179, Loss: 0.39191746711730957\n",
      "Epoch 180, Loss: 0.37059327960014343\n",
      "Epoch 181, Loss: 0.4112994074821472\n",
      "Epoch 182, Loss: 0.39252662658691406\n",
      "Epoch 183, Loss: 0.30967679619789124\n",
      "Epoch 184, Loss: 0.3742111623287201\n",
      "Epoch 185, Loss: 0.36898550391197205\n",
      "Epoch 186, Loss: 0.4556528627872467\n",
      "Epoch 187, Loss: 0.4229055643081665\n",
      "Epoch 188, Loss: 0.4390023946762085\n",
      "Epoch 189, Loss: 0.43726539611816406\n",
      "Epoch 190, Loss: 0.3119366765022278\n",
      "Epoch 191, Loss: 0.5242728590965271\n",
      "Epoch 192, Loss: 0.3502507507801056\n",
      "Epoch 193, Loss: 0.3882516920566559\n",
      "Epoch 194, Loss: 0.3308085799217224\n",
      "Epoch 195, Loss: 0.24075719714164734\n",
      "Epoch 196, Loss: 0.3479805886745453\n",
      "Epoch 197, Loss: 0.3556727468967438\n",
      "Epoch 198, Loss: 0.35558071732521057\n",
      "Epoch 199, Loss: 0.3385607898235321\n",
      "Epoch 200, Loss: 0.4177592396736145\n",
      "Accuracy: 0.8343333333333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    losses.append(loss)\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "model.eval()\n",
    "y_pre = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs.squeeze() > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        y_pre.append(predicted)\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryClassificationModel().eval()\n",
    "\n",
    "# Specify the quantization configuration for the model\n",
    "# You might need to experiment with different quantization configurations\n",
    "model.qconfig = torch.quantization.get_default_qconfig('qnnpack')\n",
    "\n",
    "# Prepare the model for static quantization\n",
    "model_prepared = torch.quantization.prepare(model, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate the model\n",
    "# Assuming 'calibration_dataloader' is a DataLoader object for your calibration dataset\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_loader:\n",
    "        model_prepared(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.quantization.get_default_qconfig: This function retrieves a default quantization configuration object. The configuration includes settings for quantizing weights and activations, such as the quantization method (affine or symmetric), the number of bits to use for quantization (typically 8-bit), and the quantization range or scale.\n",
    "- 'fbgemm': This string argument specifies the backend to use for quantized tensor operations. FBGEMM is designed for x86 architectures and is optimized for servers. It supports fast, efficient operations on quantized matrices, making it suitable for deploying quantized models on server environments where performance is critical.\n",
    "- Resulting qconfig: The returned configuration is assigned to model.qconfig, applying these quantization parameters to the model during preparation (torch.quantization.prepare) and conversion (torch.quantization.convert) steps. Essentially, it instructs PyTorch on how to quantize the model's weights and activations using the FBGEMM backend, aiming for a good balance between performance and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quantized = torch.quantization.convert(model_prepared, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassificationModel(\n",
       "  (layer0): Linear(in_features=142, out_features=32, bias=True)\n",
       "  (layer1): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (layer2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- floating-point inputs have been mapped to a fixed set of integer values.\n",
    "- The scale factor is used to convert the integer values back to floating-point numbers, and the zero_point represents the integer value mapped to the real number zero. \n",
    "- The qscheme indicates the quantization scheme used, which in this case is torch.per_tensor_affine, meaning each tensor is quantized using a single scale and zero_point that applies to the entire tensor.\n",
    "- $q = round((x-zero\\_point)/scale)$ \n",
    "   - x is the original floating-point value.\n",
    "   - q is the quantized integer value.\n",
    "   - scale is a scaling factor used to map the floating-point values to the quantized space.\n",
    "   - zero_point is used to ensure zero is accurately represented after quantization and to adjust for the range of the quantized data.\n",
    "- Clamping: $q=clamp(q, q\\_min,q\\_max)$ the quantized value q is clamped to the nearest value within the allowed range\n",
    "- Inverse Quantization Process: the inverse quantization process maps the quantized integer value q back to a floating-point approximation $\\hat{x}$: $\\hat{x} = q x scale + zero\\_point$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassificationModel(\n",
       "  (layer0): QuantizedLinear(in_features=142, out_features=32, scale=10.270036697387695, zero_point=117, qscheme=torch.per_tensor_affine)\n",
       "  (layer1): QuantizedLinear(in_features=32, out_features=16, scale=3.8025708198547363, zero_point=129, qscheme=torch.per_tensor_affine)\n",
       "  (layer2): QuantizedLinear(in_features=16, out_features=1, scale=0.6736122965812683, zero_point=0, qscheme=torch.per_tensor_affine)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quantized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def AUC(model, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            output = model(data)\n",
    "            # Dequantize output if the model is quantized\n",
    "            if hasattr(output, 'dequantize'):\n",
    "                output = output.dequantize()\n",
    "            all_outputs.append(output[:, 1])  # Adjust indexing based on your output tensor structure\n",
    "            all_targets.append(targets)\n",
    "            \n",
    "    all_outputs = torch.cat(all_outputs).numpy()  # Convert to numpy for roc_auc_score\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc_score = roc_auc_score(all_targets, all_outputs)\n",
    "    \n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'quantized::linear' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear' is only available for these backends: [MPS, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:39 [backend fallback]\nQuantizedCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/quantized/cpu/qlinear.cpp:990 [kernel]\nBackendSelect: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:491 [backend fallback]\nFunctionalize: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:280 [backend fallback]\nNamed: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradOther: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:30 [backend fallback]\nAutogradCPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:34 [backend fallback]\nAutogradCUDA: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:42 [backend fallback]\nAutogradXLA: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:46 [backend fallback]\nAutogradMPS: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:54 [backend fallback]\nAutogradXPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:38 [backend fallback]\nAutogradHPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradLazy: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:50 [backend fallback]\nAutogradMeta: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:58 [backend fallback]\nTracer: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:487 [backend fallback]\nAutocastCUDA: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:354 [backend fallback]\nFuncTorchBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:815 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1073 [backend fallback]\nVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:152 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:487 [backend fallback]\nPythonDispatcher: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zr/4gzc_dcx4_5ddc8wy4z_fllm0000gn/T/ipykernel_1227/406615616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the quantized model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Ensure to write or use an existing function to evaluate your model's performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mAUC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_quantized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/zr/4gzc_dcx4_5ddc8wy4z_fllm0000gn/T/ipykernel_1227/1373367448.py\u001b[0m in \u001b[0;36mAUC\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mall_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Select only positive class probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mall_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/zr/4gzc_dcx4_5ddc8wy4z_fllm0000gn/T/ipykernel_1227/2992997060.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/ao/nn/quantized/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         return torch.ops.quantized.linear(\n\u001b[0m\u001b[1;32m    169\u001b[0m             x, self._packed_params._packed_params, self.scale, self.zero_point)\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'quantized::linear' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear' is only available for these backends: [MPS, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:39 [backend fallback]\nQuantizedCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/quantized/cpu/qlinear.cpp:990 [kernel]\nBackendSelect: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:491 [backend fallback]\nFunctionalize: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:280 [backend fallback]\nNamed: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradOther: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:30 [backend fallback]\nAutogradCPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:34 [backend fallback]\nAutogradCUDA: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:42 [backend fallback]\nAutogradXLA: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:46 [backend fallback]\nAutogradMPS: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:54 [backend fallback]\nAutogradXPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:38 [backend fallback]\nAutogradHPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradLazy: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:50 [backend fallback]\nAutogradMeta: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:58 [backend fallback]\nTracer: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:487 [backend fallback]\nAutocastCUDA: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:354 [backend fallback]\nFuncTorchBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:815 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1073 [backend fallback]\nVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:152 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:487 [backend fallback]\nPythonDispatcher: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the quantized model\n",
    "# Ensure to write or use an existing function to evaluate your model's performance\n",
    "AUC(model_quantized, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qunatisation aware training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.5\n"
     ]
    }
   ],
   "source": [
    "y_pre = []\n",
    "y_labe = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        y_pre=np.append(y_pre,outputs.numpy())\n",
    "        y_labe=np.append(y_labe,labels.numpy())\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y_labe, y_pre)\n",
    "print(f'AUC = {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe094701490>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lss = []\n",
    "for i in range(len(losses)):\n",
    "    lss.append(losses[i].detach())\n",
    "plt.plot(lss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memeory calcualtion\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y, predicted)\n",
    "print(f'AUC = {auc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env_mini",
   "language": "python",
   "name": "ml_env_mini"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
